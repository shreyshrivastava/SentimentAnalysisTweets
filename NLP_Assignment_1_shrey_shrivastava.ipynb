{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Assignment 1 (40% of grade): Sentiment Analysis from Tweets\n",
    "\n",
    "This coursework will involve you implementing functions for a text classifier, which you will train to identify the **sentiment expressed in a text** in a dataset of approx. 27,000 entries, which will be split into a 80%/20% training/test split. \n",
    "\n",
    "In this template you are given the basis for that implementation, though some of the functions are missing, which you have to fill in.\n",
    "\n",
    "Follow the instructions file **NLP_Assignment_1_Instructions.pdf** for details of each question - the outline of what needs to be achieved for each question is as below.\n",
    "\n",
    "You must submit all **ipython notebooks and extra resources you need to run the code if you've added them** in the code submission, and a **2 page report (pdf)** in the report submission on QMPlus where you report your methods and findings according to the instructions file for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/shreyshrivastava/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv                               # csv reader\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            (label, text) = parse_data_line(line)\n",
    "            raw_data.append((text, label))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label) in raw_data[:num_training_samples]:\n",
    "        train_data.append((to_feature_vector(pre_process(text)),label))\n",
    "    for (text, label) in raw_data[num_training_samples:]:\n",
    "        test_data.append((to_feature_vector(pre_process(text)),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Input and Basic preprocessing (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_data_line(data_line):\n",
    "    #checking if the length of data is greater than or equal to 2\n",
    "    if len(data_line) >= 2:\n",
    "        labels= data_line[1]  #labels at index 1 of read data\n",
    "        text_data = data_line[2]  #texts i n the index 2 of the read data\n",
    "    else:\n",
    "        labels, text_data = None, None  \n",
    "    return labels, text_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shreyshrivastava/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shreyshrivastava/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['example', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Downloaded the required nltk modules because my laptop didnt have it earlier\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def pre_process(text):  # doing the lemmatization, removing stopwords, and extracting unigrams / bigrams\n",
    "    # Converting everything to lower case for easier checking \n",
    "    text = text.lower()\n",
    "    # Remove non-alphanumeric characters and split punctuation from words\n",
    "    text = re.sub(r\"(\\w)([.,;:!?'\\\"”\\)])\", r\"\\1 \\2\", text)\n",
    "    text = re.sub(r\"([.,;:!?'\\\"“\\(\\)])(\\w)\", r\"\\1 \\2\", text)\n",
    "    tokens = text.split()\n",
    "    stp_words = set(stopwords.words('english'))\n",
    "    lemm = WordNetLemmatizer()\n",
    "    tokens = [lemm.lemmatize(token) for token in tokens if token not in stp_words] #this step is for lemmatisation   \n",
    "    return tokens  \n",
    "\n",
    "#implementation\n",
    "text_to_check = \"This is an example sentence.\"\n",
    "tokens_implementation = pre_process(text_to_check)\n",
    "print(tokens_implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Basic Feature Extraction (20 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_feature_dict={}\n",
    "def to_feature_vector(tokens):\n",
    "    feature_vector = {}\n",
    "    \n",
    "    def add_feature(feature): #i added features tothe global feature dict\n",
    "        # If the feature not in the global feature dictionary -->  i add it\n",
    "        if feature not in global_feature_dict:\n",
    "            global_feature_dict[feature] = len(global_feature_dict)    \n",
    "        # Getting the index of the feature\n",
    "        feature_index = global_feature_dict[feature]\n",
    "        # Increment the count of the feature in the local feature vector\n",
    "        feature_vector[feature_index] = feature_vector.get(feature_index, 0) + 1\n",
    "\n",
    "    # for unigrams\n",
    "    for word in tokens:\n",
    "        add_feature(word)\n",
    "    # for bigrams\n",
    "    for i in range(len(tokens) - 1):\n",
    "        # Created a tuple to represent the bigram\n",
    "        bigram = (tokens[i], tokens[i + 1])\n",
    "        # Add the bigram feature to the local feature vector\n",
    "        add_feature(bigram)\n",
    "    # Return the local feature vector for the current example\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(data): # to train ourn model\n",
    "    print(\"Training Classifier...\")\n",
    "    pipeline = Pipeline([('svc', LinearSVC(max_iter=10000, dual=True))]) #used linearSVC to train the model\n",
    "    return SklearnClassifier(pipeline).train(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Cross-validation (20 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "def cross_validate(dataset, folds):\n",
    "    results = {'precision': [], 'recall': [], 'f1': [], 'accuracy': []}\n",
    "    fold_size = int(len(dataset) / folds) + 1\n",
    "    \n",
    "    for i in range(0, len(dataset), fold_size):\n",
    "        # Splitting the data into training and testing sets for cross-validation\n",
    "        test_set = dataset[i:i + fold_size]\n",
    "        train_set = dataset[:i] + dataset[i + fold_size:]\n",
    "        # Train the classifier on the training set\n",
    "        model = train_classifier(train_set)\n",
    "        # Get the features and labels from the test set\n",
    "        test_features, test_labels = zip(*test_set)\n",
    "        # Predicting the labels on the test set\n",
    "        predicted_labels = predict_labels(test_features, model)\n",
    "        # Evaluate the performance of our model\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(test_labels, predicted_labels, average='weighted')\n",
    "        accuracy = np.mean(np.array(test_labels) == np.array(predicted_labels))\n",
    "        # Store the results for this fold\n",
    "        results['precision'].append(precision)\n",
    "        results['recall'].append(recall)\n",
    "        results['f1'].append(f1)\n",
    "        results['accuracy'].append(accuracy)\n",
    "    # Calculate and print the average results over all folds\n",
    "    average_outputs = {\n",
    "        \"avg_precision\" : np.mean(results['precision']),\n",
    "        \"avg_recall\" : np.mean(results['recall']),\n",
    "        \"avg_f1\" : np.mean(results['f1']),\n",
    "        \"avg_accuracy\" : np.mean(results['accuracy'])}\n",
    "    return average_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
    "\n",
    "def predict_labels(samples, classifier):\n",
    "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
    "    return classifier.classify_many(samples)\n",
    "\n",
    "def predict_label_from_raw(sample, classifier):\n",
    "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
    "    return classifier.classify(to_feature_vector(preProcess(reviewSample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now 0 rawData, 0 trainData, 0 testData\n",
      "Preparing the dataset...\n",
      "Now 33540 rawData, 0 trainData, 0 testData\n",
      "Preparing training and test data...\n",
      "After split, 33540 rawData, 26832 trainData, 6708 testData\n",
      "Training Samples: \n",
      "26832\n",
      "Features: \n",
      "348969\n"
     ]
    }
   ],
   "source": [
    "# initialize global lists that will be appended to by the methods below\n",
    "raw_data = []          # the filtered data from the dataset file\n",
    "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
    "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
    "\n",
    "\n",
    "# references to the data files\n",
    "data_file_path = 'sentiment-dataset.tsv'\n",
    "\n",
    "# Do the actual stuff (i.e. call the functions we've made)\n",
    "# We parse the dataset and put it in a raw data list\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing the dataset...\",sep='\\n')\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "\n",
    "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "# You do the cross validation on the 80% (training data)\n",
    "# We print the number of training samples and the number of features before the split\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing training and test data...\",sep='\\n')\n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "# We print the number of training samples and the number of features after the split\n",
    "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n",
      "Training Classifier...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'avg_precision': 0.8568994188126245,\n",
       " 'avg_recall': 0.8586024918745642,\n",
       " 'avg_f1': 0.856529943578581,\n",
       " 'avg_accuracy': 0.8586024918745642}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(train_data, 10)  # will work and output overall performance of p, r, f-score when cv implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions 5: Optimising pre-processing and feature extraction (30 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** it is advisable to implement question 5 in a separate notebook where you further develop the pre-processing and feature extraction functions you implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({148: 1, 2: 2, 2318: 1, 140003: 1, 140: 1, 290449: 1, 290450: 1, 290451: 1, 153: 2, 279: 1, 84155: 1, 7414: 1, 5395: 1, 50935: 1, 290452: 1, 290453: 1, 290454: 1, 290455: 1, 290456: 1, 290457: 1, 754: 1, 16771: 1, 290458: 1, 290459: 1, 246727: 1}, 'positive')\n",
      "Training Classifier...\n",
      "Done training!\n",
      "Precision: 0.857634\n",
      "Recall: 0.859123\n",
      "F Score:0.857643\n"
     ]
    }
   ],
   "source": [
    "# Finally, check the accuracy of your classifier by training on all the traning data\n",
    "# and testing on the test set\n",
    "# Will only work once all functions are complete\n",
    "functions_complete = True # set to True once you're happy with your methods for cross val\n",
    "if functions_complete:\n",
    "    print(test_data[0])   # have a look at the first test data instance\n",
    "    classifier = train_classifier(train_data)  # train the classifier\n",
    "    test_true = [t[1] for t in test_data]   # get the ground-truth labels from the data\n",
    "    test_pred = predict_labels([x[0] for x in test_data], classifier)  # classify the test data to get predicted labels\n",
    "    final_scores = precision_recall_fscore_support(test_true, test_pred, average='weighted') # evaluate\n",
    "    print(\"Done training!\")\n",
    "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % final_scores[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/shreyshrivastava/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
